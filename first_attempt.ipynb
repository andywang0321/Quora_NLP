{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import string\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import time\n",
    "from torch.utils.data.dataset import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306117</th>\n",
       "      <td>ffffcc4e2331aaf1e41e</td>\n",
       "      <td>What other technical skills do you need as a c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306118</th>\n",
       "      <td>ffffd431801e5a2f4861</td>\n",
       "      <td>Does MS in ECE have good job prospects in USA ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306119</th>\n",
       "      <td>ffffd48fb36b63db010c</td>\n",
       "      <td>Is foam insulation toxic?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306120</th>\n",
       "      <td>ffffec519fa37cf60c78</td>\n",
       "      <td>How can one start a research project based on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306121</th>\n",
       "      <td>ffffed09fedb5088744a</td>\n",
       "      <td>Who wins in a battle between a Wolverine and a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1306122 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          qid  \\\n",
       "0        00002165364db923c7e6   \n",
       "1        000032939017120e6e44   \n",
       "2        0000412ca6e4628ce2cf   \n",
       "3        000042bf85aa498cd78e   \n",
       "4        0000455dfa3e01eae3af   \n",
       "...                       ...   \n",
       "1306117  ffffcc4e2331aaf1e41e   \n",
       "1306118  ffffd431801e5a2f4861   \n",
       "1306119  ffffd48fb36b63db010c   \n",
       "1306120  ffffec519fa37cf60c78   \n",
       "1306121  ffffed09fedb5088744a   \n",
       "\n",
       "                                             question_text  target  \n",
       "0        How did Quebec nationalists see their province...       0  \n",
       "1        Do you have an adopted dog, how would you enco...       0  \n",
       "2        Why does velocity affect time? Does velocity a...       0  \n",
       "3        How did Otto von Guericke used the Magdeburg h...       0  \n",
       "4        Can I convert montra helicon D to a mountain b...       0  \n",
       "...                                                    ...     ...  \n",
       "1306117  What other technical skills do you need as a c...       0  \n",
       "1306118  Does MS in ECE have good job prospects in USA ...       0  \n",
       "1306119                          Is foam insulation toxic?       0  \n",
       "1306120  How can one start a research project based on ...       0  \n",
       "1306121  Who wins in a battle between a Wolverine and a...       0  \n",
       "\n",
       "[1306122 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"./data/train.csv\"\n",
    "data_csv = pd.read_csv(data_dir)\n",
    "data_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    80810\n",
       "0    80810\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insincere_rows_ = data_csv[data_csv.target == 1]\n",
    "sincere_rows_ = data_csv[data_csv.target == 0]\n",
    "\n",
    "num_insincere_ = len(insincere_rows_)\n",
    "\n",
    "balanced_data_csv = pd.concat(\n",
    "    [insincere_rows_, sincere_rows_[:num_insincere_]]\n",
    ").sample(frac = 1).reset_index(drop=True)\n",
    "\n",
    "balanced_data_csv.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = balanced_data_csv[:80_000]\n",
    "test_csv = balanced_data_csv[80_000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2196017it [00:57, 38411.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2196016 word vectors.\n",
      "Each with length: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "glove_dir = \"./data/embeddings/glove.840B.300d/glove.840B.300d.txt\"\n",
    "\n",
    "glove = {}\n",
    "\n",
    "with open(glove_dir, encoding = \"utf8\") as f:\n",
    "    for line in tqdm(f):\n",
    "        values = line.split(\" \")\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype = 'float32')\n",
    "        glove[word] = vector\n",
    "\n",
    "vocab_size = len(glove)\n",
    "embedding_size = len(glove.get('a'))\n",
    "\n",
    "print('Found %s word vectors.' % vocab_size)\n",
    "print(f'Each with length: {embedding_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2196016 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2196016/2196016 [00:05<00:00, 398606.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2196016, 300])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, embedding_size), dtype = 'float32')\n",
    "\n",
    "for i, (word, vector) in enumerate(tqdm(glove.items())):\n",
    "    embedding_matrix[i] = vector\n",
    "\n",
    "embedding_matrix = torch.from_numpy(embedding_matrix)\n",
    "embedding_matrix.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {word : ind for ind, word in enumerate(glove.keys())}\n",
    "vocab_set = set(glove.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Why', 'can', 'some', 'birds', 'fly', 'but', 'others', 'cant']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_to_list(text, vocab = vocab_set):\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.replace('/', ' ').split()\n",
    "    return [word for word in text if word in vocab_set]\n",
    "\n",
    "test_str = \"Why can some birds fly, but others can't?\"\n",
    "\n",
    "text_to_list(test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 640,   41,   85, 4244, 2981,   42,  462, 3308])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer(text_list):\n",
    "    return np.array([dictionary.get(word) for word in text_list], dtype = int)\n",
    "\n",
    "tokenizer(text_to_list(test_str)) # np.array of word indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x : tokenizer(text_to_list(x))\n",
    "label_pipeline = lambda x : x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "\n",
    "    for _label, _text in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        \n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype = torch.int)\n",
    "        text_list.append(processed_text)\n",
    "\n",
    "        offsets.append(processed_text.size(0)) # num_words\n",
    "\n",
    "    label_list = torch.tensor(label_list, dtype = torch.int8)\n",
    "    offsets = torch.tensor(offsets[:-1], dtype = torch.int16).cumsum(dim = 0)\n",
    "    text_list = torch.cat(text_list)\n",
    "\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_matrix, embed_dim, num_classes):\n",
    "        super(QuestionClassifier, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag.from_pretrained(\n",
    "            embedding_matrix, freeze = True, sparse = False\n",
    "            )\n",
    "        self.fc = nn.Linear(embed_dim, num_classes)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "model = QuestionClassifier(\n",
    "    embedding_matrix, embedding_size, num_classes\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predictied_label = model(text, offsets)\n",
    "        loss = criterion(predictied_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predictied_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
    "                \"| accuracy {:8.3f}\".format(\n",
    "                    epoch, idx, len(dataloader), total_acc / total_count\n",
    "                )\n",
    "            )\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predicted_label = model(text, offsets)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_map_style_dataset(iter_data):\n",
    "    r\"\"\"Convert iterable-style dataset to map-style dataset.\n",
    "\n",
    "    args:\n",
    "        iter_data: An iterator type object. Examples include Iterable datasets, string list, text io, generators etc.\n",
    "\n",
    "\n",
    "    Examples:\n",
    "        >>> from torchtext.datasets import IMDB\n",
    "        >>> from torchtext.data import to_map_style_dataset\n",
    "        >>> train_iter = IMDB(split='train')\n",
    "        >>> train_dataset = to_map_style_dataset(train_iter)\n",
    "        >>> file_name = '.data/EnWik9/enwik9'\n",
    "        >>> data_iter = to_map_style_dataset(open(file_name,'r'))\n",
    "    \"\"\"\n",
    "\n",
    "    # Inner class to convert iterable-style to map-style dataset\n",
    "    class _MapStyleDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, iter_data) -> None:\n",
    "            # TODO Avoid list issue #1296\n",
    "            self._data = list(iter_data)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self._data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return self._data[idx]\n",
    "\n",
    "    return _MapStyleDataset(iter_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andywang/anaconda3/envs/learnpytorch/lib/python3.11/site-packages/torch/nn/functional.py:2420: UserWarning: The operator 'aten::_embedding_bag_forward_only' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:13.)\n",
      "  ret, _, _, _ = torch.embedding_bag(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   500/ 1188 batches | accuracy    0.746\n",
      "| epoch   1 |  1000/ 1188 batches | accuracy    0.762\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time: 274.36s | valid accuracy    0.770 \n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |   500/ 1188 batches | accuracy    0.760\n",
      "| epoch   2 |  1000/ 1188 batches | accuracy    0.758\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time: 247.82s | valid accuracy    0.755 \n",
      "-----------------------------------------------------------\n",
      "| epoch   3 |   500/ 1188 batches | accuracy    0.771\n",
      "| epoch   3 |  1000/ 1188 batches | accuracy    0.769\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time: 247.71s | valid accuracy    0.775 \n",
      "-----------------------------------------------------------\n",
      "| epoch   4 |   500/ 1188 batches | accuracy    0.774\n",
      "| epoch   4 |  1000/ 1188 batches | accuracy    0.769\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time: 252.05s | valid accuracy    0.776 \n",
      "-----------------------------------------------------------\n",
      "| epoch   5 |   500/ 1188 batches | accuracy    0.770\n",
      "| epoch   5 |  1000/ 1188 batches | accuracy    0.773\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time: 249.23s | valid accuracy    0.779 \n",
      "-----------------------------------------------------------\n",
      "| epoch   6 |   500/ 1188 batches | accuracy    0.772\n",
      "| epoch   6 |  1000/ 1188 batches | accuracy    0.774\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time: 251.80s | valid accuracy    0.779 \n",
      "-----------------------------------------------------------\n",
      "| epoch   7 |   500/ 1188 batches | accuracy    0.775\n",
      "| epoch   7 |  1000/ 1188 batches | accuracy    0.771\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time: 260.96s | valid accuracy    0.778 \n",
      "-----------------------------------------------------------\n",
      "| epoch   8 |   500/ 1188 batches | accuracy    0.773\n",
      "| epoch   8 |  1000/ 1188 batches | accuracy    0.773\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time: 257.79s | valid accuracy    0.778 \n",
      "-----------------------------------------------------------\n",
      "| epoch   9 |   500/ 1188 batches | accuracy    0.774\n",
      "| epoch   9 |  1000/ 1188 batches | accuracy    0.769\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time: 258.70s | valid accuracy    0.779 \n",
      "-----------------------------------------------------------\n",
      "| epoch  10 |   500/ 1188 batches | accuracy    0.771\n",
      "| epoch  10 |  1000/ 1188 batches | accuracy    0.773\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time: 257.82s | valid accuracy    0.779 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "EPOCHS = 10\n",
    "LR = 5\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma = 0.1)\n",
    "total_accu = None\n",
    "train_iter = ((row['target'], row['question_text'])\n",
    "              for _, row in train_csv.drop(columns = [\"qid\"]).iterrows())\n",
    "test_iter = ((row['target'], row['question_text'])\n",
    "             for _, row in test_csv.drop(columns = [\"qid\"]).iterrows())\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = random_split(\n",
    "    train_dataset, [num_train, len(train_dataset) - num_train]\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    split_train_, batch_size = BATCH_SIZE, \n",
    "    shuffle = True, collate_fn = collate_batch\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    split_valid_, batch_size = BATCH_SIZE, \n",
    "    shuffle = True, collate_fn = collate_batch\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size = BATCH_SIZE, \n",
    "    shuffle = True, collate_fn = collate_batch\n",
    ")\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        total_accu = accu_val\n",
    "    print(\"-\" * 59)\n",
    "    print(\n",
    "        \"| end of epoch {:3d} | time: {:5.2f}s | \"\n",
    "        \"valid accuracy {:8.3f} \".format(\n",
    "            epoch, time.time() - epoch_start_time, accu_val\n",
    "        )\n",
    "    )\n",
    "    print(\"-\" * 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking the results of test dataset.\n",
      "test accuracy    0.768\n"
     ]
    }
   ],
   "source": [
    "print(\"checking the results of test dataset.\")\n",
    "accu_test = evaluate(test_dataloader)\n",
    "print(\"test accuracy {:8.3f}\".format(accu_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This question is Insincere.\n"
     ]
    }
   ],
   "source": [
    "quora_label = {0 : \"Sincere\", 1 : \"Insincere\"}\n",
    "\n",
    "def predict(text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text), dtype = torch.int)\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item()\n",
    "\n",
    "example = \"can a black person be racist?\"\n",
    "\n",
    "print(\"This question is %s.\" % quora_label[predict(example, text_pipeline)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learnpytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
